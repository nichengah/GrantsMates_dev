{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "134386bd-a9b3-412c-a337-c0b54fe50d7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 248-250: truncated \\UXXXXXXXX escape (909079483.py, line 14)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"\"\"\u001b[39m\n       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m (unicode error) 'unicodeescape' codec can't decode bytes in position 248-250: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Yuewen Li\n",
    "Date: 2025/07/25\n",
    "Description: this script adds the actual URL in brackets after any existing hyperlinks in a Word (.docx) document.\n",
    "\n",
    "Usage: Set the path of the input file like this:\n",
    "    input_file = r\"D:\\ä¸‹è½½\\UAlbany_Research_Contact_Detailed.docx\".\n",
    "    \n",
    "Requirements:\n",
    "Install the `python-docx` library using the command: \n",
    "    pip install python-docx\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "from docx import Document\n",
    "from docx.oxml.ns import qn\n",
    "from docx.shared import Pt\n",
    "from docx.oxml import OxmlElement\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "\n",
    "def add_url_parentheses_directly_after_link(doc_path, output_path):\n",
    "    \"\"\"\n",
    "    å°†URLæ‹¬å·ç›´æ¥æ·»åŠ åœ¨è¶…é“¾æ¥æ–‡æœ¬åé¢ - å¢å¼ºç‰ˆ\n",
    "    \"\"\"\n",
    "    doc = Document(doc_path)\n",
    "    total_hyperlinks = 0\n",
    "    processed_hyperlinks = 0\n",
    "    skipped_hyperlinks = 0\n",
    "\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"å¼€å§‹å¤„ç†æ–‡æ¡£: {doc_path}\")\n",
    "\n",
    "    def insert_url_after_hyperlink(paragraph, hyperlink, url, location):\n",
    "        \"\"\"åœ¨è¶…é“¾æ¥åç›´æ¥æ’å…¥URL - å¢å¼ºç‰ˆ\"\"\"\n",
    "        # å°è¯•æ‰¾åˆ°è¶…é“¾æ¥å†…çš„æ–‡æœ¬å†…å®¹\n",
    "        link_text = \"\"\n",
    "        for elem in hyperlink.iterchildren():\n",
    "            if elem.tag.endswith('r'):  # æ–‡æœ¬run\n",
    "                for t in elem.iterchildren():\n",
    "                    if t.tag.endswith('t'):  # æ–‡æœ¬å…ƒç´ \n",
    "                        if t.text:\n",
    "                            link_text += t.text\n",
    "                    elif t.tag.endswith('tab'):  # åˆ¶è¡¨ç¬¦\n",
    "                        link_text += '\\t'\n",
    "                    elif t.tag.endswith('br'):  # æ¢è¡Œç¬¦\n",
    "                        link_text += '\\n'\n",
    "\n",
    "        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡æœ¬å†…å®¹ï¼Œå°è¯•å…¶ä»–æ–¹æ³•\n",
    "        if not link_text:\n",
    "            # å°è¯•ä»è¶…é“¾æ¥å±æ€§ä¸­è·å–æ–‡æœ¬\n",
    "            instr_text = hyperlink.get(qn('w:instr')) or \"\"\n",
    "            if 'HYPERLINK' in instr_text:\n",
    "                # å°è¯•ä»åŸŸä»£ç ä¸­æå–æ–‡æœ¬\n",
    "                match = re.search(r'\\\\o \"(.*?)\"', instr_text)\n",
    "                if match:\n",
    "                    link_text = match.group(1)\n",
    "                else:\n",
    "                    # ä½œä¸ºæœ€åæ‰‹æ®µï¼Œä½¿ç”¨URLä½œä¸ºæ–‡æœ¬\n",
    "                    link_text = url\n",
    "            else:\n",
    "                link_text = \"è¶…é“¾æ¥\"\n",
    "\n",
    "        print(f\"ğŸ” [{location}] è¶…é“¾æ¥æ–‡æœ¬: '{link_text}'\")\n",
    "\n",
    "        # åˆ›å»ºæ–°runå¹¶æ’å…¥\n",
    "        new_run = OxmlElement('w:r')\n",
    "\n",
    "        # æ·»åŠ æ–‡æœ¬å±æ€§\n",
    "        rPr = OxmlElement('w:rPr')\n",
    "        new_run.append(rPr)\n",
    "\n",
    "        # æ·»åŠ æ–‡æœ¬å†…å®¹\n",
    "        t = OxmlElement('w:t')\n",
    "        t.set(qn('xml:space'), 'preserve')  # ä¿ç•™ç©ºæ ¼\n",
    "        t.text = f\" ({url})\"\n",
    "        new_run.append(t)\n",
    "\n",
    "        # è®¾ç½®æ ·å¼\n",
    "        if rPr is not None:\n",
    "            # è®¾ç½®å­—ä½“å¤§å°\n",
    "            sz = OxmlElement('w:sz')\n",
    "            sz.set(qn('w:val'), \"18\")  # 9pt * 2 = 18\n",
    "            rPr.append(sz)\n",
    "\n",
    "            # ç§»é™¤ä¸‹åˆ’çº¿\n",
    "            u = OxmlElement('w:u')\n",
    "            u.set(qn('w:val'), \"none\")\n",
    "            rPr.append(u)\n",
    "\n",
    "        # åœ¨è¶…é“¾æ¥å…ƒç´ åæ’å…¥æ–°run\n",
    "        hyperlink.addnext(new_run)\n",
    "        return True\n",
    "\n",
    "    def process_hyperlink(paragraph, hyperlink, location):\n",
    "        nonlocal total_hyperlinks, processed_hyperlinks, skipped_hyperlinks\n",
    "        total_hyperlinks += 1\n",
    "\n",
    "        # è·å–å…³ç³»ID\n",
    "        rel_id = hyperlink.get(qn('r:id'))\n",
    "        if not rel_id:\n",
    "            print(f\"âš ï¸ [{location}] è·³è¿‡æ— rel_idçš„è¶…é“¾æ¥\")\n",
    "            skipped_hyperlinks += 1\n",
    "            return\n",
    "\n",
    "        # è·å–çœŸå®URL\n",
    "        try:\n",
    "            if rel_id in doc.part.rels:\n",
    "                url = doc.part.rels[rel_id]._target\n",
    "            else:\n",
    "                # å°è¯•ä»è¶…é“¾æ¥å±æ€§ä¸­è·å–URL\n",
    "                if hyperlink.get(qn('w:instr')):\n",
    "                    instr_text = hyperlink.get(qn('w:instr'))\n",
    "                    if 'HYPERLINK' in instr_text:\n",
    "                        match = re.search(r'\"([^\"]+)\"', instr_text)\n",
    "                        if match:\n",
    "                            url = match.group(1)\n",
    "                        else:\n",
    "                            print(f\"âŒ [{location}] æ— æ³•ä»åŸŸä»£ç ä¸­æå–URL\")\n",
    "                            skipped_hyperlinks += 1\n",
    "                            return\n",
    "                else:\n",
    "                    print(f\"âŒ [{location}] rel_id={rel_id} æœªæ‰¾åˆ°å¯¹åº”å…³ç³»\")\n",
    "                    skipped_hyperlinks += 1\n",
    "                    return\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ [{location}] è·å–URLæ—¶å‡ºé”™: {str(e)}\")\n",
    "            skipped_hyperlinks += 1\n",
    "            return\n",
    "\n",
    "        # åœ¨è¶…é“¾æ¥åç›´æ¥æ’å…¥URL\n",
    "        if insert_url_after_hyperlink(paragraph, hyperlink, url, location):\n",
    "            print(f\"âœ… [{location}] å·²å¤„ç†: æ·»åŠ  ({url})\")\n",
    "            processed_hyperlinks += 1\n",
    "        else:\n",
    "            skipped_hyperlinks += 1\n",
    "\n",
    "    # å¤„ç†æ­£æ–‡æ®µè½\n",
    "    for i, paragraph in enumerate(doc.paragraphs):\n",
    "        # ä½¿ç”¨æ›´å¯é çš„XPathæŸ¥è¯¢\n",
    "        hyperlinks = paragraph._element.xpath('.//w:hyperlink|.//w:fldSimple[contains(@w:instr, \"HYPERLINK\")]')\n",
    "        for j, hyperlink in enumerate(hyperlinks):\n",
    "            location = f\"æ®µè½ {i + 1}.{j + 1}\"\n",
    "            process_hyperlink(paragraph, hyperlink, location)\n",
    "\n",
    "    # å¤„ç†è¡¨æ ¼\n",
    "    for t, table in enumerate(doc.tables):\n",
    "        for r, row in enumerate(table.rows):\n",
    "            for c, cell in enumerate(row.cells):\n",
    "                for p, paragraph in enumerate(cell.paragraphs):\n",
    "                    hyperlinks = paragraph._element.xpath(\n",
    "                        './/w:hyperlink|.//w:fldSimple[contains(@w:instr, \"HYPERLINK\")]')\n",
    "                    for h, hyperlink in enumerate(hyperlinks):\n",
    "                        location = f\"è¡¨æ ¼ {t + 1}è¡Œ{r + 1}åˆ—{c + 1}æ®µè½{p + 1}.{h + 1}\"\n",
    "                        process_hyperlink(paragraph, hyperlink, location)\n",
    "\n",
    "    # å¤„ç†é¡µçœ‰\n",
    "    for s, section in enumerate(doc.sections):\n",
    "        if section.header:\n",
    "            for i, paragraph in enumerate(section.header.paragraphs):\n",
    "                hyperlinks = paragraph._element.xpath('.//w:hyperlink|.//w:fldSimple[contains(@w:instr, \"HYPERLINK\")]')\n",
    "                for j, hyperlink in enumerate(hyperlinks):\n",
    "                    location = f\"é¡µçœ‰ {s + 1}æ®µè½{i + 1}.{j + 1}\"\n",
    "                    process_hyperlink(paragraph, hyperlink, location)\n",
    "\n",
    "    # å¤„ç†é¡µè„š\n",
    "    for s, section in enumerate(doc.sections):\n",
    "        if section.footer:\n",
    "            for i, paragraph in enumerate(section.footer.paragraphs):\n",
    "                hyperlinks = paragraph._element.xpath('.//w:hyperlink|.//w:fldSimple[contains(@w:instr, \"HYPERLINK\")]')\n",
    "                for j, hyperlink in enumerate(hyperlinks):\n",
    "                    location = f\"é¡µè„š {s + 1}æ®µè½{i + 1}.{j + 1}\"\n",
    "                    process_hyperlink(paragraph, hyperlink, location)\n",
    "\n",
    "    # ä¿å­˜æ–‡æ¡£\n",
    "    doc.save(output_path)\n",
    "\n",
    "    print(f\"\\nå¤„ç†æ‘˜è¦:\")\n",
    "    print(f\"æ€»è¶…é“¾æ¥æ•°: {total_hyperlinks}\")\n",
    "    print(f\"å·²å¤„ç†: {processed_hyperlinks}\")\n",
    "    print(f\"å·²è·³è¿‡: {skipped_hyperlinks}\")\n",
    "    print(f\"è¾“å‡ºæ–‡ä»¶: {output_path}\")\n",
    "    print(f\"{'=' * 50}\\n\")\n",
    "\n",
    "    return total_hyperlinks > 0\n",
    "\n",
    "\n",
    "def create_direct_placement_output(input_path, suffix=\"_direct_urls\"):\n",
    "    \"\"\"åˆ›å»ºç›´æ¥å®šä½URLçš„è¾“å‡ºæ–‡ä»¶\"\"\"\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_path}\")\n",
    "        return None\n",
    "\n",
    "    # ç”Ÿæˆè¾“å‡ºè·¯å¾„\n",
    "    base, ext = os.path.splitext(input_path)\n",
    "    output_path = f\"{base}{suffix}{ext}\"\n",
    "\n",
    "    # é¿å…æ–‡ä»¶åå†²çª\n",
    "    counter = 1\n",
    "    while os.path.exists(output_path):\n",
    "        output_path = f\"{base}{suffix}_{counter}{ext}\"\n",
    "        counter += 1\n",
    "\n",
    "    # å¤„ç†æ–‡æ¡£\n",
    "    found_hyperlinks = add_url_parentheses_directly_after_link(input_path, output_path)\n",
    "\n",
    "    if not found_hyperlinks:\n",
    "        print(\"\\nâš ï¸ è­¦å‘Š: æœªåœ¨æ–‡æ¡£ä¸­æ‰¾åˆ°ä»»ä½•è¶…é“¾æ¥\")\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "    # è¾“å…¥æ–‡ä»¶è·¯å¾„\n",
    "    input_file = r\"D:\\ä¸‹è½½\\UAlbany_Research_Contact_Detailed.docx\"\n",
    "\n",
    "    print(f\"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "    print(f\"è„šæœ¬ç›®å½•: {script_dir}\")\n",
    "    print(f\"è¾“å…¥æ–‡ä»¶: {input_file}\")\n",
    "\n",
    "    # åˆ›å»ºæ–°æ–‡ä»¶å¹¶å¤„ç†\n",
    "    output_file = create_direct_placement_output(input_file)\n",
    "\n",
    "    if output_file:\n",
    "        print(f\"âœ… å¤„ç†å®Œæˆ! è¾“å‡ºæ–‡ä»¶: {output_file}\")\n",
    "        print(\"URLæ‹¬å·å·²ç›´æ¥æ·»åŠ åœ¨è¶…é“¾æ¥æ–‡æœ¬åé¢\")\n",
    "\n",
    "        # åœ¨Windowsä¸Šè‡ªåŠ¨æ‰“å¼€æ–‡ä»¶\n",
    "        if sys.platform == 'win32':\n",
    "            os.startfile(output_file)\n",
    "    else:\n",
    "        print(\"âŒ å¤„ç†å¤±è´¥\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b7c7a7f-6699-4548-b311-170a181128f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 220\u001b[39m\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output_path\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m     script_dir = os.path.dirname(os.path.abspath(\u001b[34;43m__file__\u001b[39;49m))\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# è¾“å…¥æ–‡ä»¶è·¯å¾„\u001b[39;00m\n\u001b[32m    223\u001b[39m     input_file = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:/Users/ææœˆé›¯/PycharmProjects/PythonProject1/GrantsMates_dev/add_hyperlinks/AWARD_REVIEW_&_NEGOTIATION.docx\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Yuewen Li\n",
    "Date: 2025/07/25\n",
    "Description: this script adds the actual URL in brackets after any existing hyperlinks in a Word (.docx) document.\n",
    "\n",
    "Usage: Set the path of the input file like this:\n",
    "    input_file = r\"D:/ä¸‹è½½/UAlbany_Research_Contact_Detailed.docx\".\n",
    "    \n",
    "Requirements:\n",
    "Install the `python-docx` library using the command: \n",
    "    pip install python-docx\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "from docx import Document\n",
    "from docx.oxml.ns import qn\n",
    "from docx.shared import Pt\n",
    "from docx.oxml import OxmlElement\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "\n",
    "def add_url_parentheses_directly_after_link(doc_path, output_path):\n",
    "    \"\"\"\n",
    "    å°†URLæ‹¬å·ç›´æ¥æ·»åŠ åœ¨è¶…é“¾æ¥æ–‡æœ¬åé¢ - å¢å¼ºç‰ˆ\n",
    "    \"\"\"\n",
    "    doc = Document(doc_path)\n",
    "    total_hyperlinks = 0\n",
    "    processed_hyperlinks = 0\n",
    "    skipped_hyperlinks = 0\n",
    "\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"å¼€å§‹å¤„ç†æ–‡æ¡£: {doc_path}\")\n",
    "\n",
    "    def insert_url_after_hyperlink(paragraph, hyperlink, url, location):\n",
    "        \"\"\"åœ¨è¶…é“¾æ¥åç›´æ¥æ’å…¥URL - å¢å¼ºç‰ˆ\"\"\"\n",
    "        # å°è¯•æ‰¾åˆ°è¶…é“¾æ¥å†…çš„æ–‡æœ¬å†…å®¹\n",
    "        link_text = \"\"\n",
    "        for elem in hyperlink.iterchildren():\n",
    "            if elem.tag.endswith('r'):  # æ–‡æœ¬run\n",
    "                for t in elem.iterchildren():\n",
    "                    if t.tag.endswith('t'):  # æ–‡æœ¬å…ƒç´ \n",
    "                        if t.text:\n",
    "                            link_text += t.text\n",
    "                    elif t.tag.endswith('tab'):  # åˆ¶è¡¨ç¬¦\n",
    "                        link_text += '\\t'\n",
    "                    elif t.tag.endswith('br'):  # æ¢è¡Œç¬¦\n",
    "                        link_text += '\\n'\n",
    "\n",
    "        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡æœ¬å†…å®¹ï¼Œå°è¯•å…¶ä»–æ–¹æ³•\n",
    "        if not link_text:\n",
    "            # å°è¯•ä»è¶…é“¾æ¥å±æ€§ä¸­è·å–æ–‡æœ¬\n",
    "            instr_text = hyperlink.get(qn('w:instr')) or \"\"\n",
    "            if 'HYPERLINK' in instr_text:\n",
    "                # å°è¯•ä»åŸŸä»£ç ä¸­æå–æ–‡æœ¬\n",
    "                match = re.search(r'\\\\o \"(.*?)\"', instr_text)\n",
    "                if match:\n",
    "                    link_text = match.group(1)\n",
    "                else:\n",
    "                    # ä½œä¸ºæœ€åæ‰‹æ®µï¼Œä½¿ç”¨URLä½œä¸ºæ–‡æœ¬\n",
    "                    link_text = url\n",
    "            else:\n",
    "                link_text = \"è¶…é“¾æ¥\"\n",
    "\n",
    "        print(f\"ğŸ” [{location}] è¶…é“¾æ¥æ–‡æœ¬: '{link_text}'\")\n",
    "\n",
    "        # åˆ›å»ºæ–°runå¹¶æ’å…¥\n",
    "        new_run = OxmlElement('w:r')\n",
    "\n",
    "        # æ·»åŠ æ–‡æœ¬å±æ€§\n",
    "        rPr = OxmlElement('w:rPr')\n",
    "        new_run.append(rPr)\n",
    "\n",
    "        # æ·»åŠ æ–‡æœ¬å†…å®¹\n",
    "        t = OxmlElement('w:t')\n",
    "        t.set(qn('xml:space'), 'preserve')  # ä¿ç•™ç©ºæ ¼\n",
    "        t.text = f\" ({url})\"\n",
    "        new_run.append(t)\n",
    "\n",
    "        # è®¾ç½®æ ·å¼\n",
    "        if rPr is not None:\n",
    "            # è®¾ç½®å­—ä½“å¤§å°\n",
    "            sz = OxmlElement('w:sz')\n",
    "            sz.set(qn('w:val'), \"18\")  # 9pt * 2 = 18\n",
    "            rPr.append(sz)\n",
    "\n",
    "            # ç§»é™¤ä¸‹åˆ’çº¿\n",
    "            u = OxmlElement('w:u')\n",
    "            u.set(qn('w:val'), \"none\")\n",
    "            rPr.append(u)\n",
    "\n",
    "        # åœ¨è¶…é“¾æ¥å…ƒç´ åæ’å…¥æ–°run\n",
    "        hyperlink.addnext(new_run)\n",
    "        return True\n",
    "\n",
    "    def process_hyperlink(paragraph, hyperlink, location):\n",
    "        nonlocal total_hyperlinks, processed_hyperlinks, skipped_hyperlinks\n",
    "        total_hyperlinks += 1\n",
    "\n",
    "        # è·å–å…³ç³»ID\n",
    "        rel_id = hyperlink.get(qn('r:id'))\n",
    "        if not rel_id:\n",
    "            print(f\"âš ï¸ [{location}] è·³è¿‡æ— rel_idçš„è¶…é“¾æ¥\")\n",
    "            skipped_hyperlinks += 1\n",
    "            return\n",
    "\n",
    "        # è·å–çœŸå®URL\n",
    "        try:\n",
    "            if rel_id in doc.part.rels:\n",
    "                url = doc.part.rels[rel_id]._target\n",
    "            else:\n",
    "                # å°è¯•ä»è¶…é“¾æ¥å±æ€§ä¸­è·å–URL\n",
    "                if hyperlink.get(qn('w:instr')):\n",
    "                    instr_text = hyperlink.get(qn('w:instr'))\n",
    "                    if 'HYPERLINK' in instr_text:\n",
    "                        match = re.search(r'\"([^\"]+)\"', instr_text)\n",
    "                        if match:\n",
    "                            url = match.group(1)\n",
    "                        else:\n",
    "                            print(f\"âŒ [{location}] æ— æ³•ä»åŸŸä»£ç ä¸­æå–URL\")\n",
    "                            skipped_hyperlinks += 1\n",
    "                            return\n",
    "                else:\n",
    "                    print(f\"âŒ [{location}] rel_id={rel_id} æœªæ‰¾åˆ°å¯¹åº”å…³ç³»\")\n",
    "                    skipped_hyperlinks += 1\n",
    "                    return\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ [{location}] è·å–URLæ—¶å‡ºé”™: {str(e)}\")\n",
    "            skipped_hyperlinks += 1\n",
    "            return\n",
    "\n",
    "        # åœ¨è¶…é“¾æ¥åç›´æ¥æ’å…¥URL\n",
    "        if insert_url_after_hyperlink(paragraph, hyperlink, url, location):\n",
    "            print(f\"âœ… [{location}] å·²å¤„ç†: æ·»åŠ  ({url})\")\n",
    "            processed_hyperlinks += 1\n",
    "        else:\n",
    "            skipped_hyperlinks += 1\n",
    "\n",
    "    # å¤„ç†æ­£æ–‡æ®µè½\n",
    "    for i, paragraph in enumerate(doc.paragraphs):\n",
    "        # ä½¿ç”¨æ›´å¯é çš„XPathæŸ¥è¯¢\n",
    "        hyperlinks = paragraph._element.xpath('.//w:hyperlink|.//w:fldSimple[contains(@w:instr, \"HYPERLINK\")]')\n",
    "        for j, hyperlink in enumerate(hyperlinks):\n",
    "            location = f\"æ®µè½ {i + 1}.{j + 1}\"\n",
    "            process_hyperlink(paragraph, hyperlink, location)\n",
    "\n",
    "    # å¤„ç†è¡¨æ ¼\n",
    "    for t, table in enumerate(doc.tables):\n",
    "        for r, row in enumerate(table.rows):\n",
    "            for c, cell in enumerate(row.cells):\n",
    "                for p, paragraph in enumerate(cell.paragraphs):\n",
    "                    hyperlinks = paragraph._element.xpath(\n",
    "                        './/w:hyperlink|.//w:fldSimple[contains(@w:instr, \"HYPERLINK\")]')\n",
    "                    for h, hyperlink in enumerate(hyperlinks):\n",
    "                        location = f\"è¡¨æ ¼ {t + 1}è¡Œ{r + 1}åˆ—{c + 1}æ®µè½{p + 1}.{h + 1}\"\n",
    "                        process_hyperlink(paragraph, hyperlink, location)\n",
    "\n",
    "    # å¤„ç†é¡µçœ‰\n",
    "    for s, section in enumerate(doc.sections):\n",
    "        if section.header:\n",
    "            for i, paragraph in enumerate(section.header.paragraphs):\n",
    "                hyperlinks = paragraph._element.xpath('.//w:hyperlink|.//w:fldSimple[contains(@w:instr, \"HYPERLINK\")]')\n",
    "                for j, hyperlink in enumerate(hyperlinks):\n",
    "                    location = f\"é¡µçœ‰ {s + 1}æ®µè½{i + 1}.{j + 1}\"\n",
    "                    process_hyperlink(paragraph, hyperlink, location)\n",
    "\n",
    "    # å¤„ç†é¡µè„š\n",
    "    for s, section in enumerate(doc.sections):\n",
    "        if section.footer:\n",
    "            for i, paragraph in enumerate(section.footer.paragraphs):\n",
    "                hyperlinks = paragraph._element.xpath('.//w:hyperlink|.//w:fldSimple[contains(@w:instr, \"HYPERLINK\")]')\n",
    "                for j, hyperlink in enumerate(hyperlinks):\n",
    "                    location = f\"é¡µè„š {s + 1}æ®µè½{i + 1}.{j + 1}\"\n",
    "                    process_hyperlink(paragraph, hyperlink, location)\n",
    "\n",
    "    # ä¿å­˜æ–‡æ¡£\n",
    "    doc.save(output_path)\n",
    "\n",
    "    print(f\"\\nå¤„ç†æ‘˜è¦:\")\n",
    "    print(f\"æ€»è¶…é“¾æ¥æ•°: {total_hyperlinks}\")\n",
    "    print(f\"å·²å¤„ç†: {processed_hyperlinks}\")\n",
    "    print(f\"å·²è·³è¿‡: {skipped_hyperlinks}\")\n",
    "    print(f\"è¾“å‡ºæ–‡ä»¶: {output_path}\")\n",
    "    print(f\"{'=' * 50}\\n\")\n",
    "\n",
    "    return total_hyperlinks > 0\n",
    "\n",
    "\n",
    "def create_direct_placement_output(input_path, suffix=\"_direct_urls\"):\n",
    "    \"\"\"åˆ›å»ºç›´æ¥å®šä½URLçš„è¾“å‡ºæ–‡ä»¶\"\"\"\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_path}\")\n",
    "        return None\n",
    "\n",
    "    # ç”Ÿæˆè¾“å‡ºè·¯å¾„\n",
    "    base, ext = os.path.splitext(input_path)\n",
    "    output_path = f\"{base}{suffix}{ext}\"\n",
    "\n",
    "    # é¿å…æ–‡ä»¶åå†²çª\n",
    "    counter = 1\n",
    "    while os.path.exists(output_path):\n",
    "        output_path = f\"{base}{suffix}_{counter}{ext}\"\n",
    "        counter += 1\n",
    "\n",
    "    # å¤„ç†æ–‡æ¡£\n",
    "    found_hyperlinks = add_url_parentheses_directly_after_link(input_path, output_path)\n",
    "\n",
    "    if not found_hyperlinks:\n",
    "        print(\"\\nâš ï¸ è­¦å‘Š: æœªåœ¨æ–‡æ¡£ä¸­æ‰¾åˆ°ä»»ä½•è¶…é“¾æ¥\")\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "    # è¾“å…¥æ–‡ä»¶è·¯å¾„\n",
    "    input_file = r\"C:/Users/ææœˆé›¯/PycharmProjects/PythonProject1/GrantsMates_dev/add_hyperlinks/AWARD_REVIEW_&_NEGOTIATION.docx\"\n",
    "\n",
    "    print(f\"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "    print(f\"è„šæœ¬ç›®å½•: {script_dir}\")\n",
    "    print(f\"è¾“å…¥æ–‡ä»¶: {input_file}\")\n",
    "\n",
    "    # åˆ›å»ºæ–°æ–‡ä»¶å¹¶å¤„ç†\n",
    "    output_file = create_direct_placement_output(input_file)\n",
    "\n",
    "    if output_file:\n",
    "        print(f\"âœ… å¤„ç†å®Œæˆ! è¾“å‡ºæ–‡ä»¶: {output_file}\")\n",
    "        print(\"URLæ‹¬å·å·²ç›´æ¥æ·»åŠ åœ¨è¶…é“¾æ¥æ–‡æœ¬åé¢\")\n",
    "\n",
    "        # åœ¨Windowsä¸Šè‡ªåŠ¨æ‰“å¼€æ–‡ä»¶\n",
    "        if sys.platform == 'win32':\n",
    "            os.startfile(output_file)\n",
    "    else:\n",
    "        print(\"âŒ å¤„ç†å¤±è´¥\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02a6da75-ca99-48a7-a04e-a672b80fc2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å½“å‰å·¥ä½œç›®å½•: C:\\Users\\ææœˆé›¯\\PycharmProjects\\PythonProject1\\GrantsMates_dev\\add_hyperlinks\n",
      "è„šæœ¬ç›®å½•: C:\\Users\\ææœˆé›¯\\PycharmProjects\\PythonProject1\\GrantsMates_dev\\add_hyperlinks\n",
      "è¾“å…¥æ–‡ä»¶: C:/Users/ææœˆé›¯/PycharmProjects/PythonProject1/GrantsMates_dev/add_hyperlinks/AWARD_REVIEW_&_NEGOTIATION.docx\n",
      "\n",
      "==================================================\n",
      "å¼€å§‹å¤„ç†æ–‡æ¡£: C:/Users/ææœˆé›¯/PycharmProjects/PythonProject1/GrantsMates_dev/add_hyperlinks/AWARD_REVIEW_&_NEGOTIATION.docx\n",
      "ğŸ” [æ®µè½ 8.1] è¶…é“¾æ¥æ–‡æœ¬: 'IRB'\n",
      "âœ… [æ®µè½ 8.1] å·²å¤„ç†: æ·»åŠ  (https://www.albany.edu/research-economic-development/researcher-guidance/human-participants)\n",
      "ğŸ” [æ®µè½ 8.2] è¶…é“¾æ¥æ–‡æœ¬: 'IACUC'\n",
      "âœ… [æ®µè½ 8.2] å·²å¤„ç†: æ·»åŠ  (https://www.albany.edu/research-economic-development/researcher-guidance/care-use-animals)\n",
      "ğŸ” [æ®µè½ 8.3] è¶…é“¾æ¥æ–‡æœ¬: 'annual conflict of interest disclosure'\n",
      "âœ… [æ®µè½ 8.3] å·²å¤„ç†: æ·»åŠ  (https://www.albany.edu/research-economic-development/researcher-guidance/regulatory-research-compliance)\n",
      "ğŸ” [æ®µè½ 10.1] è¶…é“¾æ¥æ–‡æœ¬: 'contracts@albany.edu'\n",
      "âœ… [æ®µè½ 10.1] å·²å¤„ç†: æ·»åŠ  (mailto:contracts@albany.edu)\n",
      "\n",
      "å¤„ç†æ‘˜è¦:\n",
      "æ€»è¶…é“¾æ¥æ•°: 4\n",
      "å·²å¤„ç†: 4\n",
      "å·²è·³è¿‡: 0\n",
      "è¾“å‡ºæ–‡ä»¶: C:/Users/ææœˆé›¯/PycharmProjects/PythonProject1/GrantsMates_dev/add_hyperlinks/AWARD_REVIEW_&_NEGOTIATION_direct_urls.docx\n",
      "==================================================\n",
      "\n",
      "âœ… å¤„ç†å®Œæˆ! è¾“å‡ºæ–‡ä»¶: C:/Users/ææœˆé›¯/PycharmProjects/PythonProject1/GrantsMates_dev/add_hyperlinks/AWARD_REVIEW_&_NEGOTIATION_direct_urls.docx\n",
      "URLæ‹¬å·å·²ç›´æ¥æ·»åŠ åœ¨è¶…é“¾æ¥æ–‡æœ¬åé¢\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Yuewen Li\n",
    "Date: 2025/07/25\n",
    "Description: this script adds the actual URL in brackets after any existing hyperlinks in a Word (.docx) document.\n",
    "\n",
    "Usage: Set the path of the input file like this:\n",
    "    input_file = r\"D:/ä¸‹è½½/UAlbany_Research_Contact_Detailed.docx\".\n",
    "    \n",
    "Requirements:\n",
    "Install the `python-docx` library using the command: \n",
    "    pip install python-docx\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "from docx import Document\n",
    "from docx.oxml.ns import qn\n",
    "from docx.shared import Pt\n",
    "from docx.oxml import OxmlElement\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "\n",
    "def add_url_parentheses_directly_after_link(doc_path, output_path):\n",
    "    \"\"\"\n",
    "    å°†URLæ‹¬å·ç›´æ¥æ·»åŠ åœ¨è¶…é“¾æ¥æ–‡æœ¬åé¢ - å¢å¼ºç‰ˆ\n",
    "    \"\"\"\n",
    "    doc = Document(doc_path)\n",
    "    total_hyperlinks = 0\n",
    "    processed_hyperlinks = 0\n",
    "    skipped_hyperlinks = 0\n",
    "\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"å¼€å§‹å¤„ç†æ–‡æ¡£: {doc_path}\")\n",
    "\n",
    "    def insert_url_after_hyperlink(paragraph, hyperlink, url, location):\n",
    "        \"\"\"åœ¨è¶…é“¾æ¥åç›´æ¥æ’å…¥URL - å¢å¼ºç‰ˆ\"\"\"\n",
    "        # å°è¯•æ‰¾åˆ°è¶…é“¾æ¥å†…çš„æ–‡æœ¬å†…å®¹\n",
    "        link_text = \"\"\n",
    "        for elem in hyperlink.iterchildren():\n",
    "            if elem.tag.endswith('r'):  # æ–‡æœ¬run\n",
    "                for t in elem.iterchildren():\n",
    "                    if t.tag.endswith('t'):  # æ–‡æœ¬å…ƒç´ \n",
    "                        if t.text:\n",
    "                            link_text += t.text\n",
    "                    elif t.tag.endswith('tab'):  # åˆ¶è¡¨ç¬¦\n",
    "                        link_text += '\\t'\n",
    "                    elif t.tag.endswith('br'):  # æ¢è¡Œç¬¦\n",
    "                        link_text += '\\n'\n",
    "\n",
    "        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡æœ¬å†…å®¹ï¼Œå°è¯•å…¶ä»–æ–¹æ³•\n",
    "        if not link_text:\n",
    "            # å°è¯•ä»è¶…é“¾æ¥å±æ€§ä¸­è·å–æ–‡æœ¬\n",
    "            instr_text = hyperlink.get(qn('w:instr')) or \"\"\n",
    "            if 'HYPERLINK' in instr_text:\n",
    "                # å°è¯•ä»åŸŸä»£ç ä¸­æå–æ–‡æœ¬\n",
    "                match = re.search(r'\\\\o \"(.*?)\"', instr_text)\n",
    "                if match:\n",
    "                    link_text = match.group(1)\n",
    "                else:\n",
    "                    # ä½œä¸ºæœ€åæ‰‹æ®µï¼Œä½¿ç”¨URLä½œä¸ºæ–‡æœ¬\n",
    "                    link_text = url\n",
    "            else:\n",
    "                link_text = \"è¶…é“¾æ¥\"\n",
    "\n",
    "        print(f\"ğŸ” [{location}] è¶…é“¾æ¥æ–‡æœ¬: '{link_text}'\")\n",
    "\n",
    "        # åˆ›å»ºæ–°runå¹¶æ’å…¥\n",
    "        new_run = OxmlElement('w:r')\n",
    "\n",
    "        # æ·»åŠ æ–‡æœ¬å±æ€§\n",
    "        rPr = OxmlElement('w:rPr')\n",
    "        new_run.append(rPr)\n",
    "\n",
    "        # æ·»åŠ æ–‡æœ¬å†…å®¹\n",
    "        t = OxmlElement('w:t')\n",
    "        t.set(qn('xml:space'), 'preserve')  # ä¿ç•™ç©ºæ ¼\n",
    "        t.text = f\" ({url})\"\n",
    "        new_run.append(t)\n",
    "\n",
    "        # è®¾ç½®æ ·å¼\n",
    "        if rPr is not None:\n",
    "            # è®¾ç½®å­—ä½“å¤§å°\n",
    "            sz = OxmlElement('w:sz')\n",
    "            sz.set(qn('w:val'), \"18\")  # 9pt * 2 = 18\n",
    "            rPr.append(sz)\n",
    "\n",
    "            # ç§»é™¤ä¸‹åˆ’çº¿\n",
    "            u = OxmlElement('w:u')\n",
    "            u.set(qn('w:val'), \"none\")\n",
    "            rPr.append(u)\n",
    "\n",
    "        # åœ¨è¶…é“¾æ¥å…ƒç´ åæ’å…¥æ–°run\n",
    "        hyperlink.addnext(new_run)\n",
    "        return True\n",
    "\n",
    "    def process_hyperlink(paragraph, hyperlink, location):\n",
    "        nonlocal total_hyperlinks, processed_hyperlinks, skipped_hyperlinks\n",
    "        total_hyperlinks += 1\n",
    "\n",
    "        # è·å–å…³ç³»ID\n",
    "        rel_id = hyperlink.get(qn('r:id'))\n",
    "        if not rel_id:\n",
    "            print(f\"âš ï¸ [{location}] è·³è¿‡æ— rel_idçš„è¶…é“¾æ¥\")\n",
    "            skipped_hyperlinks += 1\n",
    "            return\n",
    "\n",
    "        # è·å–çœŸå®URL\n",
    "        try:\n",
    "            if rel_id in doc.part.rels:\n",
    "                url = doc.part.rels[rel_id]._target\n",
    "            else:\n",
    "                # å°è¯•ä»è¶…é“¾æ¥å±æ€§ä¸­è·å–URL\n",
    "                if hyperlink.get(qn('w:instr')):\n",
    "                    instr_text = hyperlink.get(qn('w:instr'))\n",
    "                    if 'HYPERLINK' in instr_text:\n",
    "                        match = re.search(r'\"([^\"]+)\"', instr_text)\n",
    "                        if match:\n",
    "                            url = match.group(1)\n",
    "                        else:\n",
    "                            print(f\"âŒ [{location}] æ— æ³•ä»åŸŸä»£ç ä¸­æå–URL\")\n",
    "                            skipped_hyperlinks += 1\n",
    "                            return\n",
    "                else:\n",
    "                    print(f\"âŒ [{location}] rel_id={rel_id} æœªæ‰¾åˆ°å¯¹åº”å…³ç³»\")\n",
    "                    skipped_hyperlinks += 1\n",
    "                    return\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ [{location}] è·å–URLæ—¶å‡ºé”™: {str(e)}\")\n",
    "            skipped_hyperlinks += 1\n",
    "            return\n",
    "\n",
    "        # åœ¨è¶…é“¾æ¥åç›´æ¥æ’å…¥URL\n",
    "        if insert_url_after_hyperlink(paragraph, hyperlink, url, location):\n",
    "            print(f\"âœ… [{location}] å·²å¤„ç†: æ·»åŠ  ({url})\")\n",
    "            processed_hyperlinks += 1\n",
    "        else:\n",
    "            skipped_hyperlinks += 1\n",
    "\n",
    "    # å¤„ç†æ­£æ–‡æ®µè½\n",
    "    for i, paragraph in enumerate(doc.paragraphs):\n",
    "        # ä½¿ç”¨æ›´å¯é çš„XPathæŸ¥è¯¢\n",
    "        hyperlinks = paragraph._element.xpath('.//w:hyperlink|.//w:fldSimple[contains(@w:instr, \"HYPERLINK\")]')\n",
    "        for j, hyperlink in enumerate(hyperlinks):\n",
    "            location = f\"æ®µè½ {i + 1}.{j + 1}\"\n",
    "            process_hyperlink(paragraph, hyperlink, location)\n",
    "\n",
    "    # å¤„ç†è¡¨æ ¼\n",
    "    for t, table in enumerate(doc.tables):\n",
    "        for r, row in enumerate(table.rows):\n",
    "            for c, cell in enumerate(row.cells):\n",
    "                for p, paragraph in enumerate(cell.paragraphs):\n",
    "                    hyperlinks = paragraph._element.xpath(\n",
    "                        './/w:hyperlink|.//w:fldSimple[contains(@w:instr, \"HYPERLINK\")]')\n",
    "                    for h, hyperlink in enumerate(hyperlinks):\n",
    "                        location = f\"è¡¨æ ¼ {t + 1}è¡Œ{r + 1}åˆ—{c + 1}æ®µè½{p + 1}.{h + 1}\"\n",
    "                        process_hyperlink(paragraph, hyperlink, location)\n",
    "\n",
    "    # å¤„ç†é¡µçœ‰\n",
    "    for s, section in enumerate(doc.sections):\n",
    "        if section.header:\n",
    "            for i, paragraph in enumerate(section.header.paragraphs):\n",
    "                hyperlinks = paragraph._element.xpath('.//w:hyperlink|.//w:fldSimple[contains(@w:instr, \"HYPERLINK\")]')\n",
    "                for j, hyperlink in enumerate(hyperlinks):\n",
    "                    location = f\"é¡µçœ‰ {s + 1}æ®µè½{i + 1}.{j + 1}\"\n",
    "                    process_hyperlink(paragraph, hyperlink, location)\n",
    "\n",
    "    # å¤„ç†é¡µè„š\n",
    "    for s, section in enumerate(doc.sections):\n",
    "        if section.footer:\n",
    "            for i, paragraph in enumerate(section.footer.paragraphs):\n",
    "                hyperlinks = paragraph._element.xpath('.//w:hyperlink|.//w:fldSimple[contains(@w:instr, \"HYPERLINK\")]')\n",
    "                for j, hyperlink in enumerate(hyperlinks):\n",
    "                    location = f\"é¡µè„š {s + 1}æ®µè½{i + 1}.{j + 1}\"\n",
    "                    process_hyperlink(paragraph, hyperlink, location)\n",
    "\n",
    "    # ä¿å­˜æ–‡æ¡£\n",
    "    doc.save(output_path)\n",
    "\n",
    "    print(f\"\\nå¤„ç†æ‘˜è¦:\")\n",
    "    print(f\"æ€»è¶…é“¾æ¥æ•°: {total_hyperlinks}\")\n",
    "    print(f\"å·²å¤„ç†: {processed_hyperlinks}\")\n",
    "    print(f\"å·²è·³è¿‡: {skipped_hyperlinks}\")\n",
    "    print(f\"è¾“å‡ºæ–‡ä»¶: {output_path}\")\n",
    "    print(f\"{'=' * 50}\\n\")\n",
    "\n",
    "    return total_hyperlinks > 0\n",
    "\n",
    "\n",
    "def create_direct_placement_output(input_path, suffix=\"_direct_urls\"):\n",
    "    \"\"\"åˆ›å»ºç›´æ¥å®šä½URLçš„è¾“å‡ºæ–‡ä»¶\"\"\"\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_path}\")\n",
    "        return None\n",
    "\n",
    "    # ç”Ÿæˆè¾“å‡ºè·¯å¾„\n",
    "    base, ext = os.path.splitext(input_path)\n",
    "    output_path = f\"{base}{suffix}{ext}\"\n",
    "\n",
    "    # é¿å…æ–‡ä»¶åå†²çª\n",
    "    counter = 1\n",
    "    while os.path.exists(output_path):\n",
    "        output_path = f\"{base}{suffix}_{counter}{ext}\"\n",
    "        counter += 1\n",
    "\n",
    "    # å¤„ç†æ–‡æ¡£\n",
    "    found_hyperlinks = add_url_parentheses_directly_after_link(input_path, output_path)\n",
    "\n",
    "    if not found_hyperlinks:\n",
    "        print(\"\\nâš ï¸ è­¦å‘Š: æœªåœ¨æ–‡æ¡£ä¸­æ‰¾åˆ°ä»»ä½•è¶…é“¾æ¥\")\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•\n",
    "    script_dir = os.getcwd()\n",
    "\n",
    "    # è¾“å…¥æ–‡ä»¶è·¯å¾„\n",
    "    input_file = r\"C:/Users/ææœˆé›¯/PycharmProjects/PythonProject1/GrantsMates_dev/add_hyperlinks/AWARD_REVIEW_&_NEGOTIATION.docx\"\n",
    "\n",
    "    print(f\"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "    print(f\"è„šæœ¬ç›®å½•: {script_dir}\")\n",
    "    print(f\"è¾“å…¥æ–‡ä»¶: {input_file}\")\n",
    "\n",
    "    # åˆ›å»ºæ–°æ–‡ä»¶å¹¶å¤„ç†\n",
    "    output_file = create_direct_placement_output(input_file)\n",
    "\n",
    "    if output_file:\n",
    "        print(f\"âœ… å¤„ç†å®Œæˆ! è¾“å‡ºæ–‡ä»¶: {output_file}\")\n",
    "        print(\"URLæ‹¬å·å·²ç›´æ¥æ·»åŠ åœ¨è¶…é“¾æ¥æ–‡æœ¬åé¢\")\n",
    "\n",
    "        # åœ¨Windowsä¸Šè‡ªåŠ¨æ‰“å¼€æ–‡ä»¶\n",
    "        if sys.platform == 'win32':\n",
    "            os.startfile(output_file)\n",
    "    else:\n",
    "        print(\"âŒ å¤„ç†å¤±è´¥\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484567dd-7213-422c-9c89-2b2dc90074b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
